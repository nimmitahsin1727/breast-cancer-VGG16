{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from glob import glob\n",
    "from skimage.io import imread\n",
    "from os import listdir\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = \"D:/university/concordia/Winter 22/Machine Learning/Project/breast cancer/dataset/\"\n",
    "folder = listdir(base_path)\n",
    "len(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277524"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_images = 0\n",
    "for n in range(len(folder)):\n",
    "    patient_id = folder[n]\n",
    "    for c in [0, 1]:\n",
    "        patient_path = base_path + patient_id \n",
    "        class_path = patient_path + \"/\" + str(c) + \"/\"\n",
    "        subfiles = listdir(class_path)\n",
    "        total_images += len(subfiles)\n",
    "        \n",
    "total_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the image_path, patient_id and the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>path</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10253</td>\n",
       "      <td>D:/university/concordia/Winter 22/Machine Lear...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10253</td>\n",
       "      <td>D:/university/concordia/Winter 22/Machine Lear...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10253</td>\n",
       "      <td>D:/university/concordia/Winter 22/Machine Lear...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10253</td>\n",
       "      <td>D:/university/concordia/Winter 22/Machine Lear...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10253</td>\n",
       "      <td>D:/university/concordia/Winter 22/Machine Lear...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient_id                                               path target\n",
       "0      10253  D:/university/concordia/Winter 22/Machine Lear...      0\n",
       "1      10253  D:/university/concordia/Winter 22/Machine Lear...      0\n",
       "2      10253  D:/university/concordia/Winter 22/Machine Lear...      0\n",
       "3      10253  D:/university/concordia/Winter 22/Machine Lear...      0\n",
       "4      10253  D:/university/concordia/Winter 22/Machine Lear...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(index=np.arange(0, total_images), columns=[\"patient_id\", \"path\", \"target\"])\n",
    "\n",
    "k = 0\n",
    "for n in range(len(folder)):\n",
    "    patient_id = folder[n]\n",
    "    patient_path = base_path + patient_id \n",
    "    for c in [0,1]:\n",
    "        class_path = patient_path + \"/\" + str(c) + \"/\"\n",
    "        subfiles = listdir(class_path)\n",
    "        for m in range(len(subfiles)):\n",
    "            image_path = subfiles[m]\n",
    "            data.iloc[k][\"path\"] = class_path + image_path\n",
    "            data.iloc[k][\"target\"] = c\n",
    "            data.iloc[k][\"patient_id\"] = patient_id\n",
    "            k += 1  \n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create non_cancer_data & cancer_data. Then, merged them in sliced_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2000\n",
      "Name: target, dtype: int64\n",
      "1    2000\n",
      "Name: target, dtype: int64\n",
      "1    2000\n",
      "0    2000\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "non_cancer_data = data.query(\"target == 0\").head(2000)\n",
    "print(non_cancer_data['target'].value_counts())\n",
    "cancer_data = data.query(\"target == 1\").head(2000)\n",
    "print(cancer_data['target'].value_counts())\n",
    "sliced_data = pd.concat([non_cancer_data,cancer_data])\n",
    "print(sliced_data['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    2000\n",
      "0    2000\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(sliced_data['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sliced_data.target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sliced_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4000 entries, 0 to 9253\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   patient_id  4000 non-null   object\n",
      " 1   path        4000 non-null   object\n",
      " 2   target      4000 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 125.0+ KB\n"
     ]
    }
   ],
   "source": [
    "sliced_data.head()\n",
    "sliced_data.loc[:, \"target\"] = data.target.astype(np.str)\n",
    "sliced_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_paths = sliced_data.path.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train_ids, test_ids = train_test_split(unique_paths,\n",
    "                                           test_size=0.2,\n",
    "                                           random_state=0)\n",
    "train_ids, valid_ids = train_test_split(sub_train_ids, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now, we're taking 72.0% for training, 8.0% for validation, 20.0% for testing\n"
     ]
    }
   ],
   "source": [
    "print(f\"Now, we're taking {round(len(train_ids)/unique_paths.shape[0]*100, 1)}% for training, {round(len(valid_ids)/unique_paths.shape[0]*100,1)}% for validation, {round(len(test_ids)/unique_paths.shape[0]*100,1)}% for testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2880, 320, 800\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(train_ids)}, {len(valid_ids)}, {len(test_ids)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set shape: (2880, 3)\n",
      "test set shape: (800, 3)\n",
      "validation set shape: (320, 3)\n"
     ]
    }
   ],
   "source": [
    "train_df = sliced_data.loc[sliced_data.path.isin(train_ids),:].copy()\n",
    "test_df = sliced_data.loc[sliced_data.path.isin(test_ids),:].copy()\n",
    "valid_df = sliced_data.loc[sliced_data.path.isin(valid_ids),:].copy()\n",
    "\n",
    "print(f\"train set shape: {train_df.shape}\")\n",
    "print(f\"test set shape: {test_df.shape}\")\n",
    "print(f\"validation set shape: {valid_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   rotation_range = 40, \n",
    "                                   width_shift_range = 0.2, \n",
    "                                   height_shift_range = 0.2, \n",
    "                                   shear_range = 0.2, \n",
    "                                   zoom_range = 0.2, \n",
    "                                   horizontal_flip = True, \n",
    "                                   vertical_flip =True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (224,224)\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2880 validated image filenames belonging to 2 classes.\n",
      "Found 320 validated image filenames belonging to 2 classes.\n",
      "Found 800 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col = 'path', \n",
    "    y_col ='target',\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "valid_batches = valid_datagen.flow_from_dataframe(\n",
    "    valid_df,\n",
    "    x_col = 'path', \n",
    "    y_col ='target',\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_batches = test_datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    x_col = 'path', \n",
    "    y_col ='target',\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target distributions \n",
    "Let's take a look at the target distribution difference of the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,3,figsize=(20,5))\n",
    "sns.countplot(train_df.target, ax=ax[0], palette=\"Reds\")\n",
    "ax[0].set_title(\"Train data\")\n",
    "sns.countplot(valid_df.target, ax=ax[1], palette=\"Blues\")\n",
    "ax[1].set_title(\"Valid data\")\n",
    "sns.countplot(test_df.target, ax=ax[2], palette=\"Greens\");\n",
    "ax[2].set_title(\"Test data\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load VGG model with imagenet trained weights and without classifier/fully connected layers. We will use this as feature extractor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.engine.functional.Functional'>\n"
     ]
    }
   ],
   "source": [
    "vgg_base_model = tf.keras.applications.vgg16.VGG16(\n",
    "    weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(224, 224, 3),\n",
    ")\n",
    "print(type(vgg_base_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make loaded layers as non-trainable. This is important as we want to work with pre-trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 0\n",
      "Non-trainable params: 138,357,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in vgg_base_model.layers:\n",
    "    layer.trainable = False\n",
    "vgg_base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add all layers to model except the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = keras.models.Sequential()\n",
    "for layer in vgg_base_model.layers[0:-1]:\n",
    "    vgg_model.add(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a last classification layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.add(layers.Dense(1, activation=\"sigmoid\", name='output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " output (Dense)              (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,264,641\n",
      "Trainable params: 4,097\n",
      "Non-trainable params: 134,260,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate= 0.0001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoints = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"Breast_Cancer_VGG16_model.weights.best.h5\", \n",
    "    save_best_only=True, \n",
    "    verbose = 1, \n",
    "    mode='max', \n",
    "    monitor='val_accuracy'\n",
    ")\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\",\n",
    "    patience=5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    model_checkpoints,\n",
    "    early_stopping\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.6597 - accuracy: 0.6368\n",
      "Epoch 1: val_accuracy improved from -inf to 0.70000, saving model to Breast_Cancer_VGG16_model.weights.best.h5\n",
      "45/45 [==============================] - 326s 7s/step - loss: 0.6597 - accuracy: 0.6368 - val_loss: 0.6496 - val_accuracy: 0.7000\n",
      "Epoch 2/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.6032 - accuracy: 0.7521\n",
      "Epoch 2: val_accuracy improved from 0.70000 to 0.74063, saving model to Breast_Cancer_VGG16_model.weights.best.h5\n",
      "45/45 [==============================] - 325s 7s/step - loss: 0.6032 - accuracy: 0.7521 - val_loss: 0.6154 - val_accuracy: 0.7406\n",
      "Epoch 3/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.5620 - accuracy: 0.7747\n",
      "Epoch 3: val_accuracy improved from 0.74063 to 0.76875, saving model to Breast_Cancer_VGG16_model.weights.best.h5\n",
      "45/45 [==============================] - 340s 8s/step - loss: 0.5620 - accuracy: 0.7747 - val_loss: 0.5886 - val_accuracy: 0.7688\n",
      "Epoch 4/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.5328 - accuracy: 0.7872\n",
      "Epoch 4: val_accuracy improved from 0.76875 to 0.79062, saving model to Breast_Cancer_VGG16_model.weights.best.h5\n",
      "45/45 [==============================] - 331s 7s/step - loss: 0.5328 - accuracy: 0.7872 - val_loss: 0.5681 - val_accuracy: 0.7906\n",
      "Epoch 5/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.5084 - accuracy: 0.7997\n",
      "Epoch 5: val_accuracy did not improve from 0.79062\n",
      "45/45 [==============================] - 333s 7s/step - loss: 0.5084 - accuracy: 0.7997 - val_loss: 0.5519 - val_accuracy: 0.7906\n",
      "Epoch 6/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4932 - accuracy: 0.7955\n",
      "Epoch 6: val_accuracy improved from 0.79062 to 0.80313, saving model to Breast_Cancer_VGG16_model.weights.best.h5\n",
      "45/45 [==============================] - 299s 7s/step - loss: 0.4932 - accuracy: 0.7955 - val_loss: 0.5395 - val_accuracy: 0.8031\n",
      "Epoch 7/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4776 - accuracy: 0.8059\n",
      "Epoch 7: val_accuracy did not improve from 0.80313\n",
      "45/45 [==============================] - 294s 7s/step - loss: 0.4776 - accuracy: 0.8059 - val_loss: 0.5281 - val_accuracy: 0.7969\n",
      "Epoch 8/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4680 - accuracy: 0.8073\n",
      "Epoch 8: val_accuracy did not improve from 0.80313\n",
      "45/45 [==============================] - 290s 6s/step - loss: 0.4680 - accuracy: 0.8073 - val_loss: 0.5197 - val_accuracy: 0.7906\n",
      "Epoch 9/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4555 - accuracy: 0.8104\n",
      "Epoch 9: val_accuracy did not improve from 0.80313\n",
      "45/45 [==============================] - 292s 6s/step - loss: 0.4555 - accuracy: 0.8104 - val_loss: 0.5119 - val_accuracy: 0.8031\n",
      "Epoch 10/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4521 - accuracy: 0.8083\n",
      "Epoch 10: val_accuracy did not improve from 0.80313\n",
      "45/45 [==============================] - 289s 6s/step - loss: 0.4521 - accuracy: 0.8083 - val_loss: 0.5060 - val_accuracy: 0.7875\n",
      "Epoch 11/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4447 - accuracy: 0.8108\n",
      "Epoch 11: val_accuracy improved from 0.80313 to 0.80937, saving model to Breast_Cancer_VGG16_model.weights.best.h5\n",
      "45/45 [==============================] - 290s 6s/step - loss: 0.4447 - accuracy: 0.8108 - val_loss: 0.4988 - val_accuracy: 0.8094\n",
      "Epoch 12/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4346 - accuracy: 0.8153\n",
      "Epoch 12: val_accuracy did not improve from 0.80937\n",
      "45/45 [==============================] - 291s 6s/step - loss: 0.4346 - accuracy: 0.8153 - val_loss: 0.4963 - val_accuracy: 0.7906\n",
      "Epoch 13/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4274 - accuracy: 0.8170\n",
      "Epoch 13: val_accuracy did not improve from 0.80937\n",
      "45/45 [==============================] - 291s 6s/step - loss: 0.4274 - accuracy: 0.8170 - val_loss: 0.4907 - val_accuracy: 0.7969\n",
      "Epoch 14/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4263 - accuracy: 0.8188\n",
      "Epoch 14: val_accuracy did not improve from 0.80937\n",
      "45/45 [==============================] - 294s 7s/step - loss: 0.4263 - accuracy: 0.8188 - val_loss: 0.4888 - val_accuracy: 0.8031\n",
      "Epoch 15/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4180 - accuracy: 0.8257\n",
      "Epoch 15: val_accuracy did not improve from 0.80937\n",
      "45/45 [==============================] - 292s 6s/step - loss: 0.4180 - accuracy: 0.8257 - val_loss: 0.4791 - val_accuracy: 0.8000\n",
      "Epoch 16/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4176 - accuracy: 0.8236\n",
      "Epoch 16: val_accuracy improved from 0.80937 to 0.81250, saving model to Breast_Cancer_VGG16_model.weights.best.h5\n",
      "45/45 [==============================] - 291s 6s/step - loss: 0.4176 - accuracy: 0.8236 - val_loss: 0.4758 - val_accuracy: 0.8125\n",
      "Epoch 17/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4076 - accuracy: 0.8243\n",
      "Epoch 17: val_accuracy improved from 0.81250 to 0.81875, saving model to Breast_Cancer_VGG16_model.weights.best.h5\n",
      "45/45 [==============================] - 291s 6s/step - loss: 0.4076 - accuracy: 0.8243 - val_loss: 0.4757 - val_accuracy: 0.8188\n",
      "Epoch 18/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4107 - accuracy: 0.8250\n",
      "Epoch 18: val_accuracy did not improve from 0.81875\n",
      "45/45 [==============================] - 290s 6s/step - loss: 0.4107 - accuracy: 0.8250 - val_loss: 0.4684 - val_accuracy: 0.8094\n",
      "Epoch 19/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4069 - accuracy: 0.8264\n",
      "Epoch 19: val_accuracy did not improve from 0.81875\n",
      "45/45 [==============================] - 287s 6s/step - loss: 0.4069 - accuracy: 0.8264 - val_loss: 0.4693 - val_accuracy: 0.8125\n",
      "Epoch 20/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4058 - accuracy: 0.8302\n",
      "Epoch 20: val_accuracy did not improve from 0.81875\n",
      "45/45 [==============================] - 287s 6s/step - loss: 0.4058 - accuracy: 0.8302 - val_loss: 0.4623 - val_accuracy: 0.8125\n",
      "Epoch 21/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4041 - accuracy: 0.8333\n",
      "Epoch 21: val_accuracy did not improve from 0.81875\n",
      "45/45 [==============================] - 287s 6s/step - loss: 0.4041 - accuracy: 0.8333 - val_loss: 0.4692 - val_accuracy: 0.8031\n",
      "Epoch 22/100\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3990 - accuracy: 0.8326\n",
      "Epoch 22: val_accuracy did not improve from 0.81875\n",
      "45/45 [==============================] - 285s 6s/step - loss: 0.3990 - accuracy: 0.8326 - val_loss: 0.4564 - val_accuracy: 0.8188\n",
      "Epoch 22: early stopping\n"
     ]
    }
   ],
   "source": [
    "vgg_history = vgg_model.fit(train_batches, validation_data = valid_batches, epochs = 100, \n",
    "                    callbacks = [callbacks], verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.load_weights(\"Breast_Cancer_VGG16_model.weights.best.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.save(\"VGG16_mode.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
